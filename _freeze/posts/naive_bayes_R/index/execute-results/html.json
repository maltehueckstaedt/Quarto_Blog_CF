{
  "hash": "f4c5a1eeefb116b98993395db8a90b47",
  "result": {
    "markdown": "---\ntitle: \"Naive Bayes with R\"\nauthor: \"Malte Hückstädt\"\ndate: \"2023-11-01\"\ncategories: [R, mashine learning]\nformat: \n  html:\n    self-contained: true\nbibliography: Bibliothek.bib\n---\n\n\n# Introduction\n\nThe Naive Bayes classifier is a widely used and easy-to-understand machine learning algorithm that is primarily used for classification tasks. This method is based on Bayes' theorem. Bayes' theorem is a mathematical rule that is used to update the probability of an event based on existing information. It states:\n\n$$\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n$$\n\n-   $P(A|B)$ is the conditional probability of event $A$ under the condition that event $B$ has occurred.\n-   $P(B|A)$ is the conditional probability of event $B$ under the condition that event $A$ has occurred.\n-   $P(A)$ is the probability of event $A$, independent of event $B$.\n-   $P(B)$ is the probability of event $B$, independent of event $A$.\n\nIn simpler terms, Bayes' theorem states that we can calculate the probability of an event $A$, given the occurrence of an event $B$, by dividing the probability of $B$, given $A$, by the probability of $A$ itself and normalising by the probability of $B$.\n\nThe *naive* in the name of the Naive Bayes classifier refers to the fact that the algorithm makes a very simplifying assumption: It assumes that the features (properties) of a data point are independent of each other, which is often not the case, especially in the context of social science. Nevertheless, the Naive Bayes algorithm works surprisingly well in many applications.\n\nHow does the Naive Bayes algorithm work?\n\nLet's assume we have various pieces of information about the weather: these are the input variables (1) `sun`, (2) `rain` and (3) `temperature`. With these three input variables we want to predict the output variable `humid` with a Naive Bayes classifier. The probability that it will be `humid` is therefore based on the features `sun`, `rain` and `temperature` and their probabilities. The following applies:\n\n1.  we consider `Sun` as an independent event.\n\n2.  `Rain` and `temperature` depend on `sun`.\n\n3.  'Humidity' depends on all other weather events.\n\nIn a simplified example, if $P(sun=yes)=1$, the probability that it is humid is 46%. The probability that it is not humid is 54% (see @fig-bayes)[^1]\n\n[^1]: The figure is based on the one from C.Thornton: <https://users.sussex.ac.uk/~christ/crs/kr-ist/lec09a.html>\n\n![Simplified representation of the Naive Bayes algorithm](naive_bayes.svg){#fig-bayes fig-align=\"center\" width=\"772\"}\n\nThis is essentially the Naive Bayes algorithm in action. It relies on probabilities and assumptions about the dependencies between events to make predictions. It is important to note that the real Naive Bayes algorithm uses more complex models and works with more features, but the basic idea is the same: The probability of an event is calculated taking into account other events.\n\n# Anwendung\n\nJetzt, wo wir die Grundlagen des Naive Bayes algorithmus dargestellt haben. Die Titanic-Daten sind ein häufig verwendeter Datensatz in der Datenanalyse und dem maschinellen Lernen, der Informationen über die Passagiere des Schiffes Titanic enthält, einschließlich deren Überlebensstatus. In diesem Beispiel werden wir den Naive-Bayes-Klassifikator verwenden, um vorherzusagen, ob ein Passagier auf der Titanic überlebt hat oder nicht. Wie geht der Naive-Bayes-Klassifikator dabei vor?\n\n# Datenvorbereitung\n\nWir Laden die Titanic-Daten mithilfe des R-Packetes `titanic`. Dabei stellt das Paket bereits einen training und einen test-datensatz bereit, die jeweils die folgenden Variablen beinhalten:\n\n-   `PassengerId`: ID\n\n-   `Survived`: Survival 0 = No, 1 = Yes\n\n-   `Pclass`: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n\n-   `Name`: Name des Passagiers\n\n-   `Sex`: Geschlecht des Passagiers\n\n-   `Age`: Alter des Passagiers\n\n-   `SipSP`, Anzahl der siblings / spouses aboard the Titanic\n\n-   `Parch`, Anzahl der parents / children aboard the Titanic\n\n-   `Ticket`:, Ticket number\n\n-   `Fare`: Fahrgasttarif\n\n-   `Cabin`: Cabin number\n\n-   `Embarked`: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(titanic)\ntrain <- titanic_train\ntest <- titanic_test\n```\n:::\n\n\nDer Trainingsdatensatz wird zum training des Naive Bayes-Klassifikator, und der Test-Datensatz wird zur Bewertung seiner Modellgenauigkeit verwendet.\n\nWähle die relevanten Merkmale aus, die als Eingabe für den Naive-Bayes-Algorithmus dienen sollen. In diesem Fall könnten Merkmale wie Geschlecht, Alter, Ticketklasse, usw. relevant sein. Berechnung der Wahrscheinlichkeiten:\n\nDer Naive-Bayes-Algorithmus berechnet die Wahrscheinlichkeiten der Merkmale für jede Klasse, in diesem Fall \"Überlebt\" und \"Nicht überlebt\". Für jede Merkmalsklasse (Überlebt oder Nicht überlebt) wird die Wahrscheinlichkeit P(Klasse) berechnet. Anwendung des Naive Bayes-Algorithmus:\n\nFür einen neuen Passagier werden die Merkmalswahrscheinlichkeiten für jede Klasse berechnet. Der Algorithmus verwendet das Bayes'sche Theorem, um die bedingte Wahrscheinlichkeit P(Klasse \\| Merkmale) für jede Klasse zu schätzen. Klassifikation:\n\nDer Passagier wird der Klasse zugeordnet, für die die bedingte Wahrscheinlichkeit am höchsten ist. Wenn P(Überlebt \\| Merkmale) \\> P(Nicht überlebt \\| Merkmale), wird der Passagier als \"Überlebt\" klassifiziert, andernfalls als \"Nicht überlebt\". Evaluation des Modells:\n\nVerwende die Testdaten, um die Genauigkeit des Modells zu bewerten, indem du die vorhergesagten Klassifikationen mit den tatsächlichen Klassen vergleichst. Du kannst Metriken wie Genauigkeit, Präzision, Recall, F1-Score usw. verwenden.\n\n# Naive Bayes\n\n\n::: {.cell}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}